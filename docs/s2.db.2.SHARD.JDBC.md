### Tag s2.db.2.SHARD.JDBC
Database shard by Apache ShardingSphere

#### Database Sharding vs. Table Partitioning
Load balancing of microservices can be achieved by deploying multiple service instances. But then the load is concentrated at the database layer.
Basically we have two approaches to balance the load of database layer:

**_Database Sharding_** is a horizontal partitioning approach of data in databases. Each shard is held on a separate database server instance to spread load.
There are two main advantages to this horizontal partitioning approach:
* Reduce data size on each shard, make big data in database possible
* Reduce index size on each shard, make the performance highly improved

By contrast, **_Table Partitioning_** splits one or more tables by row, usually **_within a single instance of a schema and a database server_**. 
It may offer an advantage by reducing index size since it's easy to identify in which partition a particular row will be found, without first needing to search the index.
For example, the 'CustomersEast' and 'CustomersWest' tables save the customers in east and west respectively, and zip code already indicates where they will be found.
Sharding goes beyond this: it partitions the problematic table(s) in the same way, but it does this across potentially multiple instances of the schema. 
The obvious advantage would be that search load for large partitioned table can now be split across multiple servers(logic or physical), not just multiple indexes on the same logical server.

In brief, database sharding splits data to different instance while table partitioning splits data withing a instance.

There are some disadvantages:
* SQL complexity increased
* Query across shards
* Additional software required

#### ShardingSphere

It won't be very difficult to implement sharding/partitioning by adding some code manually in the project. But there are some very good OSS which can support those features.
Apache ShardingSphere is one of the OSS. We choose it because it can be integrated with SEATA.
[Vitess](https://vitess.io/) is another alternative for database sharding. And it supports Two-Phase Commit, although that's still experimental. 
It's a CNCF graduated project, it's promising. 

[Apache ShardingSphere](https://shardingsphere.apache.org/) is an ecosystem to transform any database into a distributed database system, and enhance it with sharding, elastic scaling, encryption features & more.
It supports both database sharding and table partitioning. In our case, we use ShardingSphere to implement table partition. ShardingSphere provides Spring Cloud starter:
1. add starter to pom.xml
```xml
        <dependency>
            <groupId>org.apache.shardingsphere</groupId>
            <artifactId>shardingsphere-jdbc-core-spring-boot-starter</artifactId>
        </dependency>
```
ShardingSphere supports two mode: ShardingSphere-JDBC and ShardingSphere-Proxy. The former works as a library, should be integrated with your project.
The latter works as an independent service, can be seen as a proxy of the real database. The above one is ShardingSphere-JDBC mode.

2. configure sharding rules
```yaml
spring:
  shardingsphere:
    datasource:
      names: cinemadb
      cinemadb:
        type: com.zaxxer.hikari.HikariDataSource
        username: obo
        password: obo
        jdbc-url: jdbc:h2:mem:obo;MODE=MySQL;DATABASE_TO_LOWER=TRUE;CASE_INSENSITIVE_IDENTIFIERS=TRUE
        driver-class-name: org.h2.Driver
    rules:
      sharding:
        tables:
          obo_hall:
            actual-data-nodes: cinemadb.obo_hall_$->{0..4}
            table-strategy:
              standard:
                sharding-column: cinema_id
                sharding-algorithm-name: obo-hall-inline
          obo_seat:
            actual-data-nodes: cinemadb.obo_seat_$->{0..4}
            table-strategy:
              standard:
                sharding-column: cinema_id
                sharding-algorithm-name: obo-seat-inline
            key-generate-strategy:
              column: id
              key-generator-name: snowflake
        binding-tables:
          - obo_hall,obo_seat
        broadcast-tables:
          - obo_cinema
        sharding-algorithms:
          obo-hall-inline:
            type: INLINE
            props:
              algorithm-expression: obo_hall_$->{cinema_id % 5}
          obo-seat-inline:
            type: INLINE
            props:
              algorithm-expression: obo_seat_$->{cinema_id % 5}
        key-generators:
          snowflake:
            type: snowflake
    props:
      sql-show: true
```
ShardingSphere needs to parse the SQL statement to generate new SQL statement according to the sharding rules.
For example, it needs to determine the final sharded table based on rules. ShardingSphere implements this by creating a data source proxy.
So the configuration 'spring.shardingsphere.datasource' is used to configure the data source. If database sharding is required, you should configure more than one datasource.
In our case, we just create one single datasource, and split data to more tables.

Since the SQL syntax is not always the same between different databases, ShardingSphere needs to develop SQL parser for each database. So not all databases are supported by ShardingSphere. 
ShardingSphere currently supports MySQL, PostgreSQL, SQLServer, Oracle, openGauss, and SQL dialects conforming to the SQL92 standard. 
Due to the complexity of SQL syntax, a few SQL are not supported for now.

In the above configuration, we use H2 database in MySQL compatible mode. We do so because we just want to show it as an example.
When SEATA is integrated, MySQL will still be the default database.

#### Sharding Rules
'spring.shardingsphere.rules' is used to configure rules:
* 'tables' is used to configure logic table and its sharding rules

   In the above configuration, 'obo_hall' and 'obo_seat' are the logic tables. Both of them use 'cinema_id' to shard.
   The algorithms are 'obo-hall-inline' and 'obo-seat-inline', they will be defined in 'sharding-algorithms' part.

* 'binding-tables' is used to declare the tables that are consistent in sharding rules

   In our case, 'obo_hall' and 'obo_seat' use 'cinema_id' to shard, and 'cinema_id' is their foreign key. Binding table can avoid cartesian.

* 'broadcast-tables' is used to define the tables that exist in all shards.

   Tables defined here will be copied to all the shards.

* 'sharding-algorithms' is used to define the algorithms

   INLINE is one of the built-in standard sharding algorithm that ShardingSphere supports. It provides single-key support for the sharding operation of = and IN in SQL.
   'obo_hall_$->{cinema_id % 5}' is Groovy expression, meaning obo_hall will be divided into 5 tables according to cinema_id. 
   The real tables will be obo_hall_0 to obo_hall_4, that are defined by 'actual-data-nodes: cinemadb.obo_hall_$->{0..4}'. More algorithm can be found [here](https://shardingsphere.apache.org/document/current/en/user-manual/common-config/builtin-algorithm/sharding/).

* 'key-generators' defines the key generators

   After sharding, rows will be spread to different tables/databases. If the key is generated by the database mechanism like auto-increase, sequence, rows in different shards may have same key.
   So we need a mechanism to generate global unique key. 'SNOWFLAKE' is one of the key generation algorithm. It can be used to generate 64 bit long type key.
   
   More key generator can be found [here](https://shardingsphere.apache.org/document/current/en/user-manual/common-config/builtin-algorithm/keygen/).

## Try yourself
Follow the instructions to finish the tasks
### Table Partitioning
1. start obo-eureka, obo-cinema
2. check the database initializing logs, how many tables it creates, how it inserts the data?
3. GET http://localhost:8081/obo/cinema, what's the logic sql, how many actual sql statements?
4. GET http://localhost:8081/obo/cinema/1/hall/1/seat, what's the logic sql? how many actual sql statements?